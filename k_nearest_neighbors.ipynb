{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/twitter_dataset.csv', encoding = 'latin-1')\n",
    "# dataset.head()           #show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Combinig attributes into single list of tuples and using those features create a 2D matrix \n",
    "\n",
    "features=[]\n",
    "for attributes in dataset.columns:\n",
    "    if attributes != 'label':\n",
    "        features.append(attributes)\n",
    "\n",
    "data = dataset.as_matrix(columns = features)\n",
    "# data = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Total instances : \", data.shape[0], \"\\nNumber of features : \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert label column into 1D arrray\n",
    "\n",
    "label = np.array(dataset['label'])\n",
    "# label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train Split\n",
    "\n",
    "Using 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of training instances: \", X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of testing instances: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the model\n",
    "neighbors = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors = neighbors)\n",
    "\n",
    "# Train the model using the training sets\n",
    "data = X_train\n",
    "label = y_train\n",
    "\n",
    "knn_model.fit(data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "Now our model is ready. We will test our data against given labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model.predict([X_test[1]])    #testing for single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   Now, apply the model to the entire test set and predict the label for each test example\n",
    "\n",
    "'''       \n",
    "       \n",
    "y_predict = []                       #to store prediction of each test example\n",
    "\n",
    "for test_case in range(len(X_test)): \n",
    "    label = knn_model.predict([X_test[test_case]])\n",
    "    \n",
    "    #append to the predictions list\n",
    "    y_predict.append(np.asscalar(label))\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perormance evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true negatives is C(0,0), false negatives is C(1,0), false positives is C(0,1) and true positives is C(1,1) \n",
    "conf_matrix = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_negative\n",
    "TN = conf_matrix[0][0]\n",
    "#false_negative\n",
    "FN = conf_matrix[1][0]\n",
    "#false_positive\n",
    "FP = conf_matrix[0][1]\n",
    "#true_positive\n",
    "TP = conf_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall is the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "# High Recall indicates the class is correctly recognized (small number of FN)\n",
    "recall = (TP)/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision is the the total number of correctly classified positive examples divided by the total number of predicted positive examples. \n",
    "# High Precision indicates an example labeled as positive is indeed positive (small number of FP)\n",
    "precision = (TP)/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure = (2*recall*precision)/(recall+precision)\n",
    "accuracy = (TP + TN)/(TN + FN + FP + TP)\n",
    "#accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ CLASSIFICATION PERFORMANCE OF K-NEAREST-NEIGHBORS MODEL ------ \n",
      " Recall :  96.14285714285714 %\n",
      " Precision :  95.46099290780143 %\n",
      " Accuracy :  95.75233981281498 %\n",
      " F-measure :  95.80071174377224 %\n"
     ]
    }
   ],
   "source": [
    "print(\"------ CLASSIFICATION PERFORMANCE OF K-NEAREST-NEIGHBORS MODEL ------ \"\\\n",
    "      \"\\n Recall : \", (recall*100) ,\"%\" \\\n",
    "      \"\\n Precision : \", (precision*100) ,\"%\" \\\n",
    "      \"\\n Accuracy : \", (accuracy*100) ,\"%\" \\\n",
    "      \"\\n F-measure : \", (fmeasure*100) ,\"%\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list = [[0]*5 for _ in range(max_iterations)]\n",
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors\t recall\t precision\t fmeasure\t accuracy\t\n",
      "1 \t 0.9657142857142857 \t 0.9534555712270804 \t 0.9595457771469128 \t 0.958963282937365\n",
      "2 \t 0.9414285714285714 \t 0.9791976225854383 \t 0.9599417334304442 \t 0.9604031677465803\n",
      "3 \t 0.9585714285714285 \t 0.9585714285714285 \t 0.9585714285714285 \t 0.9582433405327574\n",
      "4 \t 0.9471428571428572 \t 0.9664723032069971 \t 0.9567099567099566 \t 0.9568034557235421\n",
      "5 \t 0.9614285714285714 \t 0.9546099290780142 \t 0.9580071174377224 \t 0.9575233981281498\n",
      "6 \t 0.9485714285714286 \t 0.9665211062590975 \t 0.9574621485219899 \t 0.9575233981281498\n",
      "7 \t 0.9571428571428572 \t 0.9571428571428572 \t 0.9571428571428572 \t 0.9568034557235421\n",
      "8 \t 0.9471428571428572 \t 0.9650655021834061 \t 0.9560201874549388 \t 0.9560835133189345\n",
      "9 \t 0.9528571428571428 \t 0.9597122302158273 \t 0.9562724014336916 \t 0.9560835133189345\n",
      "10 \t 0.9457142857142857 \t 0.9650145772594753 \t 0.9552669552669553 \t 0.9553635709143269\n"
     ]
    }
   ],
   "source": [
    "print(\"neighbors\\t\",\"recall\\t\",\"precision\\t\",\"fmeasure\\t\",\"accuracy\\t\")\n",
    "max_iterations = 10\n",
    "accuracy_list = [[0]*5 for _ in range(max_iterations)]\n",
    "\n",
    "for neighbors in range (1,max_iterations+1):\n",
    "    # Generate the model\n",
    "    \n",
    "    knn_model = KNeighborsClassifier(n_neighbors = neighbors)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    data = X_train\n",
    "    label = y_train\n",
    "\n",
    "    knn_model.fit(data, label)\n",
    "    y_predict = []                       #to store prediction of each test example\n",
    "\n",
    "    for test_case in range(len(X_test)): \n",
    "        label = knn_model.predict([X_test[test_case]])\n",
    "\n",
    "        #append to the predictions list\n",
    "        y_predict.append(np.asscalar(label))\n",
    "\n",
    "    #predictions\n",
    "    conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "    #true_negative\n",
    "    TN = conf_matrix[0][0]\n",
    "    #false_negative\n",
    "    FN = conf_matrix[1][0]\n",
    "    #false_positive\n",
    "    FP = conf_matrix[0][1]\n",
    "    #true_positive\n",
    "    TP = conf_matrix[1][1]\n",
    "\n",
    "    recall = (TP)/(TP + FN)\n",
    "\n",
    "    precision = (TP)/(TP + FP)\n",
    "\n",
    "    fmeasure = (2*recall*precision)/(recall+precision)\n",
    "\n",
    "    accuracy = (TP + TN)/(TN + FN + FP + TP)\n",
    "    print(neighbors,\"\\t\",recall,\"\\t\",precision,\"\\t\",fmeasure,\"\\t\",accuracy)\n",
    "    accuracy_list[neighbors-1][0] = neighbors\n",
    "    accuracy_list[neighbors-1][1] = recall*100\n",
    "    accuracy_list[neighbors-1][2] = precision*100\n",
    "    accuracy_list[neighbors-1][3] = fmeasure*100\n",
    "    accuracy_list[neighbors-1][4] = accuracy*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours\t recall\t \tprecision\t \tfmeasure\t \taccuracy\t\n",
      "1   96.57142857142857   95.34555712270803   95.95457771469128   95.95457771469128\n",
      "2   94.14285714285714   97.91976225854383   95.99417334304442   95.99417334304442\n",
      "3   95.85714285714285   95.85714285714285   95.85714285714285   95.85714285714285\n",
      "4   94.71428571428572   96.6472303206997   95.67099567099567   95.67099567099567\n",
      "5   96.14285714285714   95.46099290780143   95.80071174377224   95.80071174377224\n",
      "6   94.85714285714286   96.65211062590974   95.74621485219899   95.74621485219899\n",
      "7   95.71428571428572   95.71428571428572   95.71428571428572   95.71428571428572\n",
      "8   94.71428571428572   96.50655021834062   95.60201874549388   95.60201874549388\n",
      "9   95.28571428571428   95.97122302158273   95.62724014336916   95.62724014336916\n",
      "10   94.57142857142857   96.50145772594753   95.52669552669553   95.52669552669553\n"
     ]
    }
   ],
   "source": [
    "print(\"neighbours\\t\",\"recall\\t\",\"\\tprecision\\t\",\"\\tfmeasure\\t\",\"\\taccuracy\\t\")\n",
    "for i in range(len(accuracy_list)):\n",
    "    print(accuracy_list[i][0],\" \",accuracy_list[i][1],\" \",accuracy_list[i][2],\" \",accuracy_list[i][3],\" \",accuracy_list[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--  -------  -------  -------  -------\n",
      " 1  96.5714  95.3456  95.9546  95.8963\n",
      " 2  94.1429  97.9198  95.9942  96.0403\n",
      " 3  95.8571  95.8571  95.8571  95.8243\n",
      " 4  94.7143  96.6472  95.671   95.6803\n",
      " 5  96.1429  95.461   95.8007  95.7523\n",
      " 6  94.8571  96.6521  95.7462  95.7523\n",
      " 7  95.7143  95.7143  95.7143  95.6803\n",
      " 8  94.7143  96.5066  95.602   95.6084\n",
      " 9  95.2857  95.9712  95.6272  95.6084\n",
      "10  94.5714  96.5015  95.5267  95.5364\n",
      "--  -------  -------  -------  -------\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
