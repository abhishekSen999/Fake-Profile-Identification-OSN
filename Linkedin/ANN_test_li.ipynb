{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <H1> ARTIFICIAL NEURAL NETWORK </H1>\n",
    "    <br>\n",
    "======================================================================================================================\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/LI_dataset.csv')\n",
    "dataset.head()          #show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinig attributes into single list of tuples and using those features create a 2D matrix \n",
    "\n",
    "features=[]\n",
    "for attributes in dataset.columns:\n",
    "    if attributes != 'label':\n",
    "        features.append(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: CREATE TEST AND TRAIN SETS\n",
    "\n",
    "We will randomly split our dataset in 80â€“20 ratio. Where 80% of the total data will be used as training set and rest 20% will be considered as test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dataset.as_matrix(columns = features)\n",
    "data=dataset[features].values\n",
    "#convert label column into 1D arrray\n",
    "\n",
    "label = np.array(dataset['label'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training instances: \", X_train.shape[0])\n",
    "print(\"Number of testing instances: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: FINE-TUNE HYPERPARAMETERS\n",
    "\n",
    "There are a number of different parameters that must be decided upon when designing an Artificial Neural Network. Among these parameters are the number of hidden layers, the number of neurons per layer, the number of training iterations, etc. Some of the important parameters in terms of training and network capacity are the number of hidden neurons, the learning rate and the activation function, were tuned first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialisations\n",
    "max_iterations=10\n",
    "number_of_hidden_layers=0\n",
    "step=2\n",
    "\n",
    "\n",
    "accuracy_list=[[0]*2 for _ in range(max_iterations)]\n",
    "# define the keras model\n",
    "\n",
    "for i in range(0,max_iterations):\n",
    "    model = Sequential()\n",
    "    # tanh and relu -check\n",
    "    \n",
    "    model.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "    \n",
    "    for j in range(number_of_hidden_layers):\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "            \n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "#     model.add(Dense(5, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # fit the keras model on the dataset\n",
    "    history=model.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "\n",
    "    # evaluate the keras model\n",
    "    _,accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(\"i\",i)\n",
    "    accuracy_list[i][0]=number_of_hidden_layers\n",
    "    accuracy_list[i][1]=accuracy\n",
    "#     accuracy_list.append[number_of_hidden_layers , accuracy]\n",
    "    \n",
    "    number_of_hidden_layers+=step\n",
    "\n",
    "#     print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(accuracy_list)):\n",
    "    print(accuracy_list[i][0],\"\\t\",accuracy_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of hidden layers vs accuracy\n",
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Activation Functions\n",
    "\n",
    "Output layer will have Sigmoid function. Different combinations of Tanh and ReLU activation functions will be used to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model1 = Sequential()\n",
    "# tanh and relu -check\n",
    "\n",
    "#add hidden layers\n",
    "#experimentally it was found that when ReLU activation function was applied to all the layers, the model gave the best result.\n",
    "model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model1.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "\n",
    "# evaluate the model\n",
    "_,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model1 = Sequential()\n",
    "# tanh and relu -check\n",
    "\n",
    "#add hidden layers\n",
    "model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "model1.add(Dense(4, activation='tanh'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model1.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "\n",
    "# evaluate the model\n",
    "_,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Number of neurons in hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iterations=10\n",
    "number_of_neurons=2\n",
    "step=2\n",
    "\n",
    "\n",
    "accuracy_list=[[0]*2 for _ in range(max_iterations)]\n",
    "# define the keras model\n",
    "\n",
    "for i in range(0,max_iterations):  \n",
    "    model2 = Sequential()\n",
    "    # tanh and relu -check\n",
    "    \n",
    "    #add hidden layers\n",
    "    model2.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model2.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "    \n",
    "    # evaluate the model\n",
    "    _,accuracy = model2.evaluate(X_test, y_test)\n",
    "\n",
    "    accuracy_list[i][0]=number_of_neurons\n",
    "    accuracy_list[i][1]=accuracy*100\n",
    "#     print('Accuracy: %.2f' % (accuracy*100))\n",
    "    print(accuracy_list[i][1])\n",
    "    number_of_neurons += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(accuracy_list)):\n",
    "    print(accuracy_list[i][0],\"\\t\",accuracy_list[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Number of Ephocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations=100\n",
    "number_of_ephocs=0\n",
    "step=10\n",
    "\n",
    "\n",
    "accuracy_list=[[0]*2 for _ in range(max_iterations)]\n",
    "# define the keras model\n",
    "\n",
    "for i in range(0,max_iterations):\n",
    "    model1 = Sequential()\n",
    "\n",
    "    model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history=model1.fit(X_train, y_train, epochs=number_of_ephocs, batch_size=150,validation_split=0.30)\n",
    "    \n",
    "    # evaluate the model\n",
    "    number_of_ephocs+=step\n",
    "    _,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "    print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: TRAIN THE FINAL MODEL\n",
    "\n",
    "Using fine-tuned hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "#Arcitecture of the ANN\n",
    "model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "history = model1.fit(X_train, y_train, epochs=375, batch_size=150,validation_split=0.30,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "_,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label = model1.predict_classes(X_test)\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.reshape(X_test[test_case:test_case+1],(6,)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: EVALUATION OF CLASSIFICATION RESULTS\n",
    "\n",
    "The classifier will be evaluted using Accuracy, Recall, Precision and F-measure. For this first, a confusion matrix will be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict =   model1.predict_classes(X_test)                #to store prediction of each test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_negative\n",
    "TN = conf_matrix[0][0]\n",
    "\n",
    "#false_negative\n",
    "FN = conf_matrix[1][0]\n",
    "\n",
    "#false_positive\n",
    "FP = conf_matrix[0][1]\n",
    "\n",
    "#true_positive\n",
    "TP = conf_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall is the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "# High Recall indicates the class is correctly recognized (small number of FN)\n",
    "\n",
    "recall = (TP)/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (TP)/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure = (2*recall*precision)/(recall+precision)\n",
    "accuracy = (TP + TN)/(TN + FN + FP + TP)\n",
    "#accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ CLASSIFICATION PERFORMANCE OF THE NEURAL NETWORKS MODEL ------ \\n\"\\\n",
    "      \"\\n Recall : \", (recall*100) ,\"%\" \\\n",
    "      \"\\n Precision : \", (precision*100) ,\"%\" \\\n",
    "      \"\\n Accuracy : \", (accuracy*100) ,\"%\" \\\n",
    "      \"\\n F-measure : \", (fmeasure*100) ,\"%\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())    #to list all data in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy and Loss plotting\n",
    "def plot(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
