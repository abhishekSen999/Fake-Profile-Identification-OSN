{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <H1> ARTIFICIAL NEURAL NETWORK </H1>\n",
    "    <br>\n",
    "======================================================================================================================\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy and Loss plotting\n",
    "def plot(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_wt</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1211</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>313</td>\n",
       "      <td>101</td>\n",
       "      <td>173</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>247</td>\n",
       "      <td>51</td>\n",
       "      <td>382</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>12341</td>\n",
       "      <td>770</td>\n",
       "      <td>1417</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name_wt  statuses_count  followers_count  friends_count  favourites_count  \\\n",
       "0  0.857143            1211               24             63                 6   \n",
       "1  0.250000             313              101            173                48   \n",
       "2  0.411765             247               51            382                50   \n",
       "3  0.611111              41                3             36                 5   \n",
       "4  0.600000           12341              770           1417                 0   \n",
       "\n",
       "   listed_count  label  \n",
       "0             6      0  \n",
       "1             0      0  \n",
       "2             4      0  \n",
       "3             0      0  \n",
       "4             8      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/twitter_dataset.csv', encoding = 'latin-1')\n",
    "dataset.head()          #show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinig attributes into single list of tuples and using those features create a 2D matrix \n",
    "\n",
    "features=[]\n",
    "for attributes in dataset.columns:\n",
    "    if attributes != 'label':\n",
    "        features.append(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: CREATE TEST AND TRAIN SETS\n",
    "\n",
    "We will randomly split our dataset in 80â€“20 ratio. Where 80% of the total data will be used as training set and rest 20% will be considered as test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dataset.as_matrix(columns = features)\n",
    "data=dataset[features].values\n",
    "#convert label column into 1D arrray\n",
    "\n",
    "label = np.array(dataset['label'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances:  5556\n",
      "Number of testing instances:  1389\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training instances: \", X_train.shape[0])\n",
    "print(\"Number of testing instances: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: FINE-TUNE HYPERPARAMETERS\n",
    "\n",
    "There are a number of different parameters that must be decided upon when designing an Artificial Neural Network. Among these parameters are the number of hidden layers, the number of neurons per layer, the number of training iterations, etc. Some of the important parameters in terms of training and network capacity are the number of hidden neurons, the learning rate and the activation function, were tuned first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5556/5556 [==============================] - 0s 33us/step - loss: 3200.7510 - accuracy: 0.3602\n",
      "Epoch 2/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 1225.4953 - accuracy: 0.1748\n",
      "Epoch 3/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 139.4003 - accuracy: 0.4568\n",
      "Epoch 4/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 47.9160 - accuracy: 0.6168\n",
      "Epoch 5/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 35.7072 - accuracy: 0.6604\n",
      "Epoch 6/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 30.1679 - accuracy: 0.6686\n",
      "Epoch 7/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 25.2738 - accuracy: 0.6848\n",
      "Epoch 8/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 20.0922 - accuracy: 0.7212\n",
      "Epoch 9/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 17.7644 - accuracy: 0.8094\n",
      "Epoch 10/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 14.6717 - accuracy: 0.8913\n",
      "Epoch 11/150\n",
      "5556/5556 [==============================] - 0s 12us/step - loss: 12.7931 - accuracy: 0.8907\n",
      "Epoch 12/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 10.7172 - accuracy: 0.9044\n",
      "Epoch 13/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 10.1325 - accuracy: 0.9039\n",
      "Epoch 14/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 9.1184 - accuracy: 0.9084\n",
      "Epoch 15/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 8.8925 - accuracy: 0.9125\n",
      "Epoch 16/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 18.7134 - accuracy: 0.9080\n",
      "Epoch 17/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 13.1495 - accuracy: 0.9086\n",
      "Epoch 18/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 7.5357 - accuracy: 0.9147\n",
      "Epoch 19/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 7.2241 - accuracy: 0.9147\n",
      "Epoch 20/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 7.3679 - accuracy: 0.9150\n",
      "Epoch 21/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 6.7851 - accuracy: 0.9165\n",
      "Epoch 22/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 6.7228 - accuracy: 0.9125\n",
      "Epoch 23/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 6.8460 - accuracy: 0.9080\n",
      "Epoch 24/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 5.8138 - accuracy: 0.9113\n",
      "Epoch 25/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 5.9434 - accuracy: 0.9156\n",
      "Epoch 26/150\n",
      "5556/5556 [==============================] - 0s 12us/step - loss: 5.2277 - accuracy: 0.9143\n",
      "Epoch 27/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 6.6023 - accuracy: 0.9062\n",
      "Epoch 28/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 10.3544 - accuracy: 0.9210\n",
      "Epoch 29/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 5.4592 - accuracy: 0.9186\n",
      "Epoch 30/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 5.1565 - accuracy: 0.9208\n",
      "Epoch 31/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 4.8692 - accuracy: 0.9177\n",
      "Epoch 32/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 4.7527 - accuracy: 0.9078\n",
      "Epoch 33/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 4.3424 - accuracy: 0.9190\n",
      "Epoch 34/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 4.0148 - accuracy: 0.9172\n",
      "Epoch 35/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 5.3138 - accuracy: 0.9055\n",
      "Epoch 36/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 5.0878 - accuracy: 0.9026\n",
      "Epoch 37/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 4.2255 - accuracy: 0.9138\n",
      "Epoch 38/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 4.3394 - accuracy: 0.9127\n",
      "Epoch 39/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 3.6201 - accuracy: 0.9122\n",
      "Epoch 40/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 4.1809 - accuracy: 0.8942\n",
      "Epoch 41/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 3.9522 - accuracy: 0.9132\n",
      "Epoch 42/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 4.0770 - accuracy: 0.9089\n",
      "Epoch 43/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 3.5920 - accuracy: 0.9086\n",
      "Epoch 44/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 3.4413 - accuracy: 0.9136\n",
      "Epoch 45/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 4.3112 - accuracy: 0.9057\n",
      "Epoch 46/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 3.5485 - accuracy: 0.9053\n",
      "Epoch 47/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 3.7447 - accuracy: 0.9145\n",
      "Epoch 48/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 3.6861 - accuracy: 0.9109\n",
      "Epoch 49/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.7083 - accuracy: 0.9095\n",
      "Epoch 50/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.6894 - accuracy: 0.9107\n",
      "Epoch 51/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.4464 - accuracy: 0.9138\n",
      "Epoch 52/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 3.6918 - accuracy: 0.9069\n",
      "Epoch 53/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.8849 - accuracy: 0.9224\n",
      "Epoch 54/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 3.0464 - accuracy: 0.9186\n",
      "Epoch 55/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.9528 - accuracy: 0.9208\n",
      "Epoch 56/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.8229 - accuracy: 0.9170\n",
      "Epoch 57/150\n",
      "5556/5556 [==============================] - 0s 12us/step - loss: 2.0454 - accuracy: 0.9194\n",
      "Epoch 58/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.9018 - accuracy: 0.9174\n",
      "Epoch 59/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 3.4574 - accuracy: 0.9156\n",
      "Epoch 60/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 4.4608 - accuracy: 0.9140\n",
      "Epoch 61/150\n",
      "5556/5556 [==============================] - 0s 12us/step - loss: 3.3938 - accuracy: 0.9201\n",
      "Epoch 62/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 4.0869 - accuracy: 0.9141\n",
      "Epoch 63/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 10.3731 - accuracy: 0.9006\n",
      "Epoch 64/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 10.1601 - accuracy: 0.9167\n",
      "Epoch 65/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.8862 - accuracy: 0.9320\n",
      "Epoch 66/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 3.2199 - accuracy: 0.9233\n",
      "Epoch 67/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 2.7637 - accuracy: 0.9294\n",
      "Epoch 68/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 1.8203 - accuracy: 0.9356\n",
      "Epoch 69/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 2.1607 - accuracy: 0.9309\n",
      "Epoch 70/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 2.0381 - accuracy: 0.9314\n",
      "Epoch 71/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 1.9663 - accuracy: 0.9386 0s - loss: 2.1320 - accuracy: 0.94\n",
      "Epoch 72/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 1.6719 - accuracy: 0.9336\n",
      "Epoch 73/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 2.3363 - accuracy: 0.9330\n",
      "Epoch 74/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 5.4278 - accuracy: 0.9037\n",
      "Epoch 75/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 2.5168 - accuracy: 0.9249\n",
      "Epoch 76/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.0614 - accuracy: 0.9201\n",
      "Epoch 77/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.8440 - accuracy: 0.9244\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.2210 - accuracy: 0.9255\n",
      "Epoch 79/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 1.5449 - accuracy: 0.9397\n",
      "Epoch 80/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.2557 - accuracy: 0.9253\n",
      "Epoch 81/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.6119 - accuracy: 0.9293\n",
      "Epoch 82/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.2753 - accuracy: 0.9311\n",
      "Epoch 83/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.0812 - accuracy: 0.9258\n",
      "Epoch 84/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.2403 - accuracy: 0.9325\n",
      "Epoch 85/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 1.6647 - accuracy: 0.9307\n",
      "Epoch 86/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.5672 - accuracy: 0.9336\n",
      "Epoch 87/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.1763 - accuracy: 0.9393\n",
      "Epoch 88/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 2.0473 - accuracy: 0.9273\n",
      "Epoch 89/150\n",
      "5556/5556 [==============================] - 0s 11us/step - loss: 10.2072 - accuracy: 0.9242\n",
      "Epoch 90/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 4.8981 - accuracy: 0.9253\n",
      "Epoch 91/150\n",
      "5556/5556 [==============================] - 0s 11us/step - loss: 3.2644 - accuracy: 0.9404\n",
      "Epoch 92/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.2126 - accuracy: 0.9431\n",
      "Epoch 93/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.4086 - accuracy: 0.9352\n",
      "Epoch 94/150\n",
      "5556/5556 [==============================] - 0s 11us/step - loss: 6.8191 - accuracy: 0.9071\n",
      "Epoch 95/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 3.4279 - accuracy: 0.9282\n",
      "Epoch 96/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.3553 - accuracy: 0.9300\n",
      "Epoch 97/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 9.5225 - accuracy: 0.8497\n",
      "Epoch 98/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.4329 - accuracy: 0.9278\n",
      "Epoch 99/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.2094 - accuracy: 0.9370\n",
      "Epoch 100/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.0930 - accuracy: 0.9329\n",
      "Epoch 101/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.9293 - accuracy: 0.9374\n",
      "Epoch 102/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 2.6867 - accuracy: 0.9312\n",
      "Epoch 103/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.0651 - accuracy: 0.9338\n",
      "Epoch 104/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 1.4947 - accuracy: 0.9345\n",
      "Epoch 105/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.0684 - accuracy: 0.9336\n",
      "Epoch 106/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.1636 - accuracy: 0.9278\n",
      "Epoch 107/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 4.8372 - accuracy: 0.9181\n",
      "Epoch 108/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.4374 - accuracy: 0.9323\n",
      "Epoch 109/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 2.5303 - accuracy: 0.9370\n",
      "Epoch 110/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 1.6109 - accuracy: 0.9402\n",
      "Epoch 111/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 1.2812 - accuracy: 0.9406\n",
      "Epoch 112/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 3.0463 - accuracy: 0.9230\n",
      "Epoch 113/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 4.1814 - accuracy: 0.9046\n",
      "Epoch 114/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 2.1731 - accuracy: 0.9343\n",
      "Epoch 115/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.9270 - accuracy: 0.9329\n",
      "Epoch 116/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 1.9944 - accuracy: 0.9318\n",
      "Epoch 117/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 2.0081 - accuracy: 0.9401\n",
      "Epoch 118/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.3438 - accuracy: 0.9408\n",
      "Epoch 119/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 2.6320 - accuracy: 0.9357\n",
      "Epoch 120/150\n",
      "5556/5556 [==============================] - 0s 9us/step - loss: 2.1483 - accuracy: 0.9428\n",
      "Epoch 121/150\n",
      "5556/5556 [==============================] - 0s 9us/step - loss: 1.3302 - accuracy: 0.9415\n",
      "Epoch 122/150\n",
      "5556/5556 [==============================] - 0s 12us/step - loss: 1.9482 - accuracy: 0.9318\n",
      "Epoch 123/150\n",
      "5556/5556 [==============================] - 0s 11us/step - loss: 1.6565 - accuracy: 0.9406\n",
      "Epoch 124/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.3884 - accuracy: 0.9415\n",
      "Epoch 125/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 1.4644 - accuracy: 0.9348\n",
      "Epoch 126/150\n",
      "5556/5556 [==============================] - 0s 10us/step - loss: 1.6373 - accuracy: 0.9397\n",
      "Epoch 127/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 1.8723 - accuracy: 0.9356\n",
      "Epoch 128/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.5340 - accuracy: 0.9399\n",
      "Epoch 129/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 1.4343 - accuracy: 0.9438\n",
      "Epoch 130/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 1.6517 - accuracy: 0.9417\n",
      "Epoch 131/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 2.4646 - accuracy: 0.9269\n",
      "Epoch 132/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 1.3538 - accuracy: 0.9410\n",
      "Epoch 133/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 1.6091 - accuracy: 0.9393\n",
      "Epoch 134/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 3.5569 - accuracy: 0.9242\n",
      "Epoch 135/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 14.4369 - accuracy: 0.9084\n",
      "Epoch 136/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 8.8716 - accuracy: 0.9302\n",
      "Epoch 137/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 2.6987 - accuracy: 0.9388\n",
      "Epoch 138/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 2.0663 - accuracy: 0.9424\n",
      "Epoch 139/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 3.7022 - accuracy: 0.9235\n",
      "Epoch 140/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 2.4032 - accuracy: 0.9318\n",
      "Epoch 141/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.6965 - accuracy: 0.9357\n",
      "Epoch 142/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.7026 - accuracy: 0.9386\n",
      "Epoch 143/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 1.9135 - accuracy: 0.9399\n",
      "Epoch 144/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.7180 - accuracy: 0.9415\n",
      "Epoch 145/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.4896 - accuracy: 0.9386\n",
      "Epoch 146/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 5.5275 - accuracy: 0.9284\n",
      "Epoch 147/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 3.2466 - accuracy: 0.9316\n",
      "Epoch 148/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 1.4815 - accuracy: 0.9390\n",
      "Epoch 149/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 1.4893 - accuracy: 0.9437\n",
      "Epoch 150/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 1.2048 - accuracy: 0.9473\n",
      "1389/1389 [==============================] - 0s 39us/step\n",
      "i 0\n",
      "Epoch 1/150\n",
      "5556/5556 [==============================] - 0s 44us/step - loss: 36.8101 - accuracy: 0.5360\n",
      "Epoch 2/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 8.4904 - accuracy: 0.6614\n",
      "Epoch 3/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 1.4196 - accuracy: 0.6199\n",
      "Epoch 4/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 1.1446 - accuracy: 0.5817\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.9025 - accuracy: 0.5772\n",
      "Epoch 6/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.8344 - accuracy: 0.6019\n",
      "Epoch 7/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.7566 - accuracy: 0.6841\n",
      "Epoch 8/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.7001 - accuracy: 0.7514\n",
      "Epoch 9/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.6799 - accuracy: 0.7779\n",
      "Epoch 10/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.6726 - accuracy: 0.7865\n",
      "Epoch 11/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.6549 - accuracy: 0.7790\n",
      "Epoch 12/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.6590 - accuracy: 0.7801\n",
      "Epoch 13/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.6384 - accuracy: 0.7799\n",
      "Epoch 14/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.6324 - accuracy: 0.7716\n",
      "Epoch 15/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.6242 - accuracy: 0.7727\n",
      "Epoch 16/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.6111 - accuracy: 0.7714\n",
      "Epoch 17/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.6083 - accuracy: 0.7707\n",
      "Epoch 18/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 0.5938 - accuracy: 0.7721\n",
      "Epoch 19/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.5786 - accuracy: 0.7631\n",
      "Epoch 20/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.5868 - accuracy: 0.7757\n",
      "Epoch 21/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.5567 - accuracy: 0.7601\n",
      "Epoch 22/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.5755 - accuracy: 0.7642\n",
      "Epoch 23/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.5670 - accuracy: 0.7624\n",
      "Epoch 24/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.5551 - accuracy: 0.7730\n",
      "Epoch 25/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.5483 - accuracy: 0.7723\n",
      "Epoch 26/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.5267 - accuracy: 0.7676\n",
      "Epoch 27/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.5424 - accuracy: 0.7745\n",
      "Epoch 28/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.5316 - accuracy: 0.7667\n",
      "Epoch 29/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.5272 - accuracy: 0.7684\n",
      "Epoch 30/150\n",
      "5556/5556 [==============================] - 0s 40us/step - loss: 0.5204 - accuracy: 0.7687\n",
      "Epoch 31/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.5163 - accuracy: 0.7768\n",
      "Epoch 32/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.5280 - accuracy: 0.7831\n",
      "Epoch 33/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 0.5055 - accuracy: 0.7903\n",
      "Epoch 34/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.5062 - accuracy: 0.7946\n",
      "Epoch 35/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4939 - accuracy: 0.7910\n",
      "Epoch 36/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.4972 - accuracy: 0.7973\n",
      "Epoch 37/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.4730 - accuracy: 0.7887\n",
      "Epoch 38/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.4924 - accuracy: 0.8000\n",
      "Epoch 39/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.4802 - accuracy: 0.7972\n",
      "Epoch 40/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 0.4934 - accuracy: 0.8029\n",
      "Epoch 41/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.4761 - accuracy: 0.7808\n",
      "Epoch 42/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4789 - accuracy: 0.7910\n",
      "Epoch 43/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.4669 - accuracy: 0.8249\n",
      "Epoch 44/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.4673 - accuracy: 0.8463\n",
      "Epoch 45/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4573 - accuracy: 0.8308\n",
      "Epoch 46/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.5367 - accuracy: 0.8373\n",
      "Epoch 47/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.4980 - accuracy: 0.8360\n",
      "Epoch 48/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4571 - accuracy: 0.8051\n",
      "Epoch 49/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.4661 - accuracy: 0.8227\n",
      "Epoch 50/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4541 - accuracy: 0.8206\n",
      "Epoch 51/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4486 - accuracy: 0.8310\n",
      "Epoch 52/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 0.4501 - accuracy: 0.8258\n",
      "Epoch 53/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4395 - accuracy: 0.8290\n",
      "Epoch 54/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4399 - accuracy: 0.8258\n",
      "Epoch 55/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.4343 - accuracy: 0.8256\n",
      "Epoch 56/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4435 - accuracy: 0.8411\n",
      "Epoch 57/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4578 - accuracy: 0.8305\n",
      "Epoch 58/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.5352 - accuracy: 0.8414\n",
      "Epoch 59/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4902 - accuracy: 0.8342\n",
      "Epoch 60/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4311 - accuracy: 0.8234\n",
      "Epoch 61/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4245 - accuracy: 0.8463\n",
      "Epoch 62/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.4362 - accuracy: 0.8067\n",
      "Epoch 63/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.4457 - accuracy: 0.8107\n",
      "Epoch 64/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4271 - accuracy: 0.8033\n",
      "Epoch 65/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.4232 - accuracy: 0.7991\n",
      "Epoch 66/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.4139 - accuracy: 0.8146\n",
      "Epoch 67/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4199 - accuracy: 0.7919\n",
      "Epoch 68/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.4195 - accuracy: 0.8026\n",
      "Epoch 69/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4558 - accuracy: 0.8063\n",
      "Epoch 70/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.4108 - accuracy: 0.8058\n",
      "Epoch 71/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4274 - accuracy: 0.8234\n",
      "Epoch 72/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.4005 - accuracy: 0.8186\n",
      "Epoch 73/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4102 - accuracy: 0.8252\n",
      "Epoch 74/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.3997 - accuracy: 0.8083\n",
      "Epoch 75/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4081 - accuracy: 0.8096\n",
      "Epoch 76/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3975 - accuracy: 0.8287\n",
      "Epoch 77/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.4141 - accuracy: 0.8629\n",
      "Epoch 78/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3659 - accuracy: 0.8611\n",
      "Epoch 79/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3371 - accuracy: 0.8647\n",
      "Epoch 80/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.3558 - accuracy: 0.8756\n",
      "Epoch 81/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3223 - accuracy: 0.8758\n",
      "Epoch 82/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.3087 - accuracy: 0.8828\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.3311 - accuracy: 0.8891\n",
      "Epoch 84/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.3189 - accuracy: 0.8983\n",
      "Epoch 85/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2947 - accuracy: 0.8954\n",
      "Epoch 86/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2919 - accuracy: 0.9021\n",
      "Epoch 87/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.3400 - accuracy: 0.8873\n",
      "Epoch 88/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2777 - accuracy: 0.8985\n",
      "Epoch 89/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3426 - accuracy: 0.8868\n",
      "Epoch 90/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3285 - accuracy: 0.8960\n",
      "Epoch 91/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.3800 - accuracy: 0.8400\n",
      "Epoch 92/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.4164 - accuracy: 0.8198\n",
      "Epoch 93/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.3538 - accuracy: 0.8391\n",
      "Epoch 94/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.3308 - accuracy: 0.8855\n",
      "Epoch 95/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.2663 - accuracy: 0.9082\n",
      "Epoch 96/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2980 - accuracy: 0.9163\n",
      "Epoch 97/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.3019 - accuracy: 0.9095\n",
      "Epoch 98/150\n",
      "5556/5556 [==============================] - 0s 13us/step - loss: 0.2796 - accuracy: 0.9165\n",
      "Epoch 99/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2757 - accuracy: 0.9161\n",
      "Epoch 100/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2520 - accuracy: 0.9239\n",
      "Epoch 101/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2577 - accuracy: 0.9006\n",
      "Epoch 102/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2898 - accuracy: 0.9098\n",
      "Epoch 103/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2484 - accuracy: 0.9203\n",
      "Epoch 104/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2759 - accuracy: 0.9183\n",
      "Epoch 105/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.3017 - accuracy: 0.9122\n",
      "Epoch 106/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2545 - accuracy: 0.9266\n",
      "Epoch 107/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2622 - accuracy: 0.9199\n",
      "Epoch 108/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2679 - accuracy: 0.9213\n",
      "Epoch 109/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2798 - accuracy: 0.9057\n",
      "Epoch 110/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.2668 - accuracy: 0.9143\n",
      "Epoch 111/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3674 - accuracy: 0.8436\n",
      "Epoch 112/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.3063 - accuracy: 0.8844\n",
      "Epoch 113/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3370 - accuracy: 0.8641\n",
      "Epoch 114/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.3575 - accuracy: 0.8319\n",
      "Epoch 115/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.3374 - accuracy: 0.8810\n",
      "Epoch 116/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.3262 - accuracy: 0.8852\n",
      "Epoch 117/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2881 - accuracy: 0.8981\n",
      "Epoch 118/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.3010 - accuracy: 0.8891\n",
      "Epoch 119/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2938 - accuracy: 0.8900\n",
      "Epoch 120/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.3427 - accuracy: 0.8963\n",
      "Epoch 121/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2587 - accuracy: 0.9055\n",
      "Epoch 122/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2633 - accuracy: 0.9170\n",
      "Epoch 123/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3125 - accuracy: 0.9260\n",
      "Epoch 124/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2733 - accuracy: 0.8929\n",
      "Epoch 125/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2824 - accuracy: 0.8799\n",
      "Epoch 126/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2996 - accuracy: 0.8972\n",
      "Epoch 127/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.3040 - accuracy: 0.8958\n",
      "Epoch 128/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.3098 - accuracy: 0.9028\n",
      "Epoch 129/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2434 - accuracy: 0.9091\n",
      "Epoch 130/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2625 - accuracy: 0.9145\n",
      "Epoch 131/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2420 - accuracy: 0.9230\n",
      "Epoch 132/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.3350 - accuracy: 0.8114\n",
      "Epoch 133/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.3213 - accuracy: 0.8907\n",
      "Epoch 134/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2954 - accuracy: 0.8873\n",
      "Epoch 135/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2815 - accuracy: 0.8929\n",
      "Epoch 136/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.2707 - accuracy: 0.8992\n",
      "Epoch 137/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2632 - accuracy: 0.8997\n",
      "Epoch 138/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2983 - accuracy: 0.9010\n",
      "Epoch 139/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2607 - accuracy: 0.8972\n",
      "Epoch 140/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2886 - accuracy: 0.8979\n",
      "Epoch 141/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2615 - accuracy: 0.9033\n",
      "Epoch 142/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.2707 - accuracy: 0.9010\n",
      "Epoch 143/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2795 - accuracy: 0.8978\n",
      "Epoch 144/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2659 - accuracy: 0.9028\n",
      "Epoch 145/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2349 - accuracy: 0.9064\n",
      "Epoch 146/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2370 - accuracy: 0.9183\n",
      "Epoch 147/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2207 - accuracy: 0.9235\n",
      "Epoch 148/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2805 - accuracy: 0.9327\n",
      "Epoch 149/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2390 - accuracy: 0.9143\n",
      "Epoch 150/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2145 - accuracy: 0.9329\n",
      "1389/1389 [==============================] - 0s 43us/step\n",
      "i 1\n",
      "Epoch 1/150\n",
      "5556/5556 [==============================] - 0s 60us/step - loss: 11.9686 - accuracy: 0.6305\n",
      "Epoch 2/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 6.1407 - accuracy: 0.6994\n",
      "Epoch 3/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 4.0467 - accuracy: 0.7781\n",
      "Epoch 4/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 2.7269 - accuracy: 0.8474\n",
      "Epoch 5/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 1.7047 - accuracy: 0.8934\n",
      "Epoch 6/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 1.0848 - accuracy: 0.8978\n",
      "Epoch 7/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.7513 - accuracy: 0.8560\n",
      "Epoch 8/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.8643 - accuracy: 0.8605\n",
      "Epoch 9/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.7303 - accuracy: 0.8780\n",
      "Epoch 10/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.8264 - accuracy: 0.8596\n",
      "Epoch 11/150\n",
      "5556/5556 [==============================] - 0s 14us/step - loss: 0.5205 - accuracy: 0.8683\n",
      "Epoch 12/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.5760 - accuracy: 0.8566\n",
      "Epoch 13/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.5476 - accuracy: 0.8719\n",
      "Epoch 14/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.4999 - accuracy: 0.8737\n",
      "Epoch 15/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.7523 - accuracy: 0.8706\n",
      "Epoch 16/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.4582 - accuracy: 0.8679\n",
      "Epoch 17/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.4792 - accuracy: 0.8652\n",
      "Epoch 18/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.6335 - accuracy: 0.8639\n",
      "Epoch 19/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.7584 - accuracy: 0.8740\n",
      "Epoch 20/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.5431 - accuracy: 0.8886\n",
      "Epoch 21/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.6523 - accuracy: 0.8744\n",
      "Epoch 22/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4261 - accuracy: 0.8861\n",
      "Epoch 23/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.4154 - accuracy: 0.8805\n",
      "Epoch 24/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.3335 - accuracy: 0.8855\n",
      "Epoch 25/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.4514 - accuracy: 0.8781\n",
      "Epoch 26/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.4055 - accuracy: 0.8839\n",
      "Epoch 27/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.3723 - accuracy: 0.9023\n",
      "Epoch 28/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.5533 - accuracy: 0.8956\n",
      "Epoch 29/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.5153 - accuracy: 0.8990\n",
      "Epoch 30/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.3615 - accuracy: 0.9062\n",
      "Epoch 31/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.4915 - accuracy: 0.8945\n",
      "Epoch 32/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.5343 - accuracy: 0.8940\n",
      "Epoch 33/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3643 - accuracy: 0.9068\n",
      "Epoch 34/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2833 - accuracy: 0.9093\n",
      "Epoch 35/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2759 - accuracy: 0.9118\n",
      "Epoch 36/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.4037 - accuracy: 0.8992\n",
      "Epoch 37/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.3276 - accuracy: 0.9075\n",
      "Epoch 38/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3416 - accuracy: 0.9053\n",
      "Epoch 39/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2649 - accuracy: 0.9107\n",
      "Epoch 40/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2527 - accuracy: 0.9179\n",
      "Epoch 41/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2562 - accuracy: 0.9210\n",
      "Epoch 42/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2735 - accuracy: 0.9174\n",
      "Epoch 43/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3298 - accuracy: 0.9131\n",
      "Epoch 44/150\n",
      "5556/5556 [==============================] - 0s 38us/step - loss: 0.8154 - accuracy: 0.8933\n",
      "Epoch 45/150\n",
      "5556/5556 [==============================] - 0s 36us/step - loss: 0.3147 - accuracy: 0.9152\n",
      "Epoch 46/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.3325 - accuracy: 0.9149\n",
      "Epoch 47/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.3614 - accuracy: 0.9109\n",
      "Epoch 48/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.4221 - accuracy: 0.9084\n",
      "Epoch 49/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.3340 - accuracy: 0.9136\n",
      "Epoch 50/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.3413 - accuracy: 0.9170\n",
      "Epoch 51/150\n",
      "5556/5556 [==============================] - 0s 32us/step - loss: 0.2758 - accuracy: 0.9237\n",
      "Epoch 52/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.3091 - accuracy: 0.9226\n",
      "Epoch 53/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3389 - accuracy: 0.9136\n",
      "Epoch 54/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2631 - accuracy: 0.9235\n",
      "Epoch 55/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2464 - accuracy: 0.9271\n",
      "Epoch 56/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.3244 - accuracy: 0.9176\n",
      "Epoch 57/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2628 - accuracy: 0.9258\n",
      "Epoch 58/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2796 - accuracy: 0.9267\n",
      "Epoch 59/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2430 - accuracy: 0.9300\n",
      "Epoch 60/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2438 - accuracy: 0.9294\n",
      "Epoch 61/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2226 - accuracy: 0.9325\n",
      "Epoch 62/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2681 - accuracy: 0.9267\n",
      "Epoch 63/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.3167 - accuracy: 0.9271\n",
      "Epoch 64/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2717 - accuracy: 0.9294\n",
      "Epoch 65/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2324 - accuracy: 0.9325\n",
      "Epoch 66/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2261 - accuracy: 0.9327\n",
      "Epoch 67/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2223 - accuracy: 0.9320\n",
      "Epoch 68/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.6046 - accuracy: 0.9176\n",
      "Epoch 69/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.3149 - accuracy: 0.9269\n",
      "Epoch 70/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2598 - accuracy: 0.9246\n",
      "Epoch 71/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2419 - accuracy: 0.9311\n",
      "Epoch 72/150\n",
      "5556/5556 [==============================] - 0s 15us/step - loss: 0.2439 - accuracy: 0.9314\n",
      "Epoch 73/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2978 - accuracy: 0.9226\n",
      "Epoch 74/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2309 - accuracy: 0.9278\n",
      "Epoch 75/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2580 - accuracy: 0.9285\n",
      "Epoch 76/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.3149 - accuracy: 0.9224\n",
      "Epoch 77/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2283 - accuracy: 0.9316\n",
      "Epoch 78/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.2708 - accuracy: 0.9285\n",
      "Epoch 79/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.2226 - accuracy: 0.9352\n",
      "Epoch 80/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.1833 - accuracy: 0.9393\n",
      "Epoch 81/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.1980 - accuracy: 0.9372\n",
      "Epoch 82/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2366 - accuracy: 0.9285\n",
      "Epoch 83/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2120 - accuracy: 0.9345\n",
      "Epoch 84/150\n",
      "5556/5556 [==============================] - 0s 32us/step - loss: 0.2932 - accuracy: 0.9285\n",
      "Epoch 85/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.2430 - accuracy: 0.9343\n",
      "Epoch 86/150\n",
      "5556/5556 [==============================] - 0s 30us/step - loss: 0.2112 - accuracy: 0.9273\n",
      "Epoch 87/150\n",
      "5556/5556 [==============================] - 0s 33us/step - loss: 0.2916 - accuracy: 0.9285\n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 38us/step - loss: 0.9691 - accuracy: 0.9149\n",
      "Epoch 89/150\n",
      "5556/5556 [==============================] - 0s 35us/step - loss: 0.2100 - accuracy: 0.9320\n",
      "Epoch 90/150\n",
      "5556/5556 [==============================] - 0s 39us/step - loss: 0.1669 - accuracy: 0.9411\n",
      "Epoch 91/150\n",
      "5556/5556 [==============================] - 0s 29us/step - loss: 0.1707 - accuracy: 0.9392\n",
      "Epoch 92/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.1914 - accuracy: 0.9368\n",
      "Epoch 93/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2010 - accuracy: 0.9388\n",
      "Epoch 94/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2006 - accuracy: 0.9365\n",
      "Epoch 95/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1748 - accuracy: 0.9419\n",
      "Epoch 96/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.1996 - accuracy: 0.9316\n",
      "Epoch 97/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2158 - accuracy: 0.9323\n",
      "Epoch 98/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.1882 - accuracy: 0.9294 0s - loss: 0.1972 - accuracy: 0.\n",
      "Epoch 99/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.2271 - accuracy: 0.9293\n",
      "Epoch 100/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.1790 - accuracy: 0.9401\n",
      "Epoch 101/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.1591 - accuracy: 0.9444\n",
      "Epoch 102/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.1761 - accuracy: 0.9424\n",
      "Epoch 103/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1717 - accuracy: 0.9447\n",
      "Epoch 104/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.1756 - accuracy: 0.9437\n",
      "Epoch 105/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.1440 - accuracy: 0.9492\n",
      "Epoch 106/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1613 - accuracy: 0.9438\n",
      "Epoch 107/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1993 - accuracy: 0.9428\n",
      "Epoch 108/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.1786 - accuracy: 0.9404\n",
      "Epoch 109/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.1718 - accuracy: 0.9415\n",
      "Epoch 110/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.1874 - accuracy: 0.9438\n",
      "Epoch 111/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.3164 - accuracy: 0.9318\n",
      "Epoch 112/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.1502 - accuracy: 0.9473\n",
      "Epoch 113/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1841 - accuracy: 0.9437\n",
      "Epoch 114/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.1687 - accuracy: 0.9449\n",
      "Epoch 115/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.1540 - accuracy: 0.9440\n",
      "Epoch 116/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2150 - accuracy: 0.9381\n",
      "Epoch 117/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1759 - accuracy: 0.9451\n",
      "Epoch 118/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.1738 - accuracy: 0.9415\n",
      "Epoch 119/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.1971 - accuracy: 0.9444\n",
      "Epoch 120/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.1868 - accuracy: 0.9422\n",
      "Epoch 121/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.1432 - accuracy: 0.9485\n",
      "Epoch 122/150\n",
      "5556/5556 [==============================] - 0s 29us/step - loss: 0.1404 - accuracy: 0.9464\n",
      "Epoch 123/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.1584 - accuracy: 0.9437\n",
      "Epoch 124/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.1399 - accuracy: 0.9453\n",
      "Epoch 125/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.1477 - accuracy: 0.9446\n",
      "Epoch 126/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.1483 - accuracy: 0.9438\n",
      "Epoch 127/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.1873 - accuracy: 0.9406\n",
      "Epoch 128/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.1818 - accuracy: 0.9390\n",
      "Epoch 129/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.1660 - accuracy: 0.9469\n",
      "Epoch 130/150\n",
      "5556/5556 [==============================] - 0s 33us/step - loss: 0.1852 - accuracy: 0.9428\n",
      "Epoch 131/150\n",
      "5556/5556 [==============================] - 0s 36us/step - loss: 0.1787 - accuracy: 0.9444\n",
      "Epoch 132/150\n",
      "5556/5556 [==============================] - 0s 35us/step - loss: 0.1609 - accuracy: 0.9437\n",
      "Epoch 133/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.2035 - accuracy: 0.9347 0s - loss: 0.1985 - accuracy: 0.\n",
      "Epoch 134/150\n",
      "5556/5556 [==============================] - 0s 33us/step - loss: 0.1977 - accuracy: 0.9377\n",
      "Epoch 135/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.2604 - accuracy: 0.9269\n",
      "Epoch 136/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 1.4386 - accuracy: 0.9213\n",
      "Epoch 137/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.1778 - accuracy: 0.9348\n",
      "Epoch 138/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.1869 - accuracy: 0.9379\n",
      "Epoch 139/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.1630 - accuracy: 0.9424\n",
      "Epoch 140/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.1651 - accuracy: 0.9417\n",
      "Epoch 141/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.1610 - accuracy: 0.9437\n",
      "Epoch 142/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.1439 - accuracy: 0.9429\n",
      "Epoch 143/150\n",
      "5556/5556 [==============================] - 0s 32us/step - loss: 0.1609 - accuracy: 0.9411\n",
      "Epoch 144/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.1441 - accuracy: 0.9462\n",
      "Epoch 145/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.1487 - accuracy: 0.9408\n",
      "Epoch 146/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.1854 - accuracy: 0.9401\n",
      "Epoch 147/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.1952 - accuracy: 0.9374\n",
      "Epoch 148/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.1389 - accuracy: 0.9453\n",
      "Epoch 149/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.1402 - accuracy: 0.9446\n",
      "Epoch 150/150\n",
      "5556/5556 [==============================] - 0s 33us/step - loss: 0.1578 - accuracy: 0.9420\n",
      "1389/1389 [==============================] - 0s 48us/step\n",
      "i 2\n",
      "Epoch 1/150\n",
      "5556/5556 [==============================] - 0s 78us/step - loss: 284.7244 - accuracy: 0.4978\n",
      "Epoch 2/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 54.8321 - accuracy: 0.4890\n",
      "Epoch 3/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 12.3451 - accuracy: 0.2669\n",
      "Epoch 4/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 3.8970 - accuracy: 0.2878\n",
      "Epoch 5/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 1.1346 - accuracy: 0.6416\n",
      "Epoch 6/150\n",
      "5556/5556 [==============================] - 0s 36us/step - loss: 0.7134 - accuracy: 0.8238\n",
      "Epoch 7/150\n",
      "5556/5556 [==============================] - 0s 30us/step - loss: 0.6467 - accuracy: 0.8350\n",
      "Epoch 8/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.5958 - accuracy: 0.8454\n",
      "Epoch 9/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.5576 - accuracy: 0.8486\n",
      "Epoch 10/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.5210 - accuracy: 0.8557\n",
      "Epoch 11/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.4938 - accuracy: 0.8609\n",
      "Epoch 12/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.4742 - accuracy: 0.8695\n",
      "Epoch 13/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.4587 - accuracy: 0.8744\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.4463 - accuracy: 0.8781\n",
      "Epoch 15/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.4354 - accuracy: 0.8816\n",
      "Epoch 16/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.4259 - accuracy: 0.8835\n",
      "Epoch 17/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.4176 - accuracy: 0.8875\n",
      "Epoch 18/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.4099 - accuracy: 0.8918\n",
      "Epoch 19/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.4024 - accuracy: 0.8933\n",
      "Epoch 20/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.3959 - accuracy: 0.8931\n",
      "Epoch 21/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.3890 - accuracy: 0.8943\n",
      "Epoch 22/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3872 - accuracy: 0.8945\n",
      "Epoch 23/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.3786 - accuracy: 0.8972\n",
      "Epoch 24/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.3747 - accuracy: 0.8963\n",
      "Epoch 25/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.3688 - accuracy: 0.8983\n",
      "Epoch 26/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.3643 - accuracy: 0.8987\n",
      "Epoch 27/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.3629 - accuracy: 0.8988\n",
      "Epoch 28/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.3608 - accuracy: 0.8947\n",
      "Epoch 29/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.3546 - accuracy: 0.8983\n",
      "Epoch 30/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.3474 - accuracy: 0.8994\n",
      "Epoch 31/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.3461 - accuracy: 0.9001\n",
      "Epoch 32/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.3431 - accuracy: 0.9003\n",
      "Epoch 33/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.3505 - accuracy: 0.8990\n",
      "Epoch 34/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.3463 - accuracy: 0.8925\n",
      "Epoch 35/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.3373 - accuracy: 0.8970\n",
      "Epoch 36/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3302 - accuracy: 0.9010\n",
      "Epoch 37/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.3251 - accuracy: 0.9024\n",
      "Epoch 38/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.3228 - accuracy: 0.9012\n",
      "Epoch 39/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.3185 - accuracy: 0.9037\n",
      "Epoch 40/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.3159 - accuracy: 0.9033\n",
      "Epoch 41/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3120 - accuracy: 0.9035\n",
      "Epoch 42/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3089 - accuracy: 0.9044\n",
      "Epoch 43/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3101 - accuracy: 0.9060\n",
      "Epoch 44/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.3058 - accuracy: 0.9048\n",
      "Epoch 45/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3063 - accuracy: 0.9023\n",
      "Epoch 46/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2998 - accuracy: 0.9051\n",
      "Epoch 47/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.2976 - accuracy: 0.9062\n",
      "Epoch 48/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2947 - accuracy: 0.9071\n",
      "Epoch 49/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2929 - accuracy: 0.9069\n",
      "Epoch 50/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.3263 - accuracy: 0.9037\n",
      "Epoch 51/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.3122 - accuracy: 0.8999\n",
      "Epoch 52/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.3004 - accuracy: 0.9015\n",
      "Epoch 53/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.2956 - accuracy: 0.9035\n",
      "Epoch 54/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.2918 - accuracy: 0.9042\n",
      "Epoch 55/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.2884 - accuracy: 0.9051\n",
      "Epoch 56/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2864 - accuracy: 0.9059\n",
      "Epoch 57/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2873 - accuracy: 0.9053\n",
      "Epoch 58/150\n",
      "5556/5556 [==============================] - 0s 31us/step - loss: 0.2816 - accuracy: 0.9091\n",
      "Epoch 59/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2797 - accuracy: 0.9096\n",
      "Epoch 60/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.2782 - accuracy: 0.9100\n",
      "Epoch 61/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2770 - accuracy: 0.9095\n",
      "Epoch 62/150\n",
      "5556/5556 [==============================] - 0s 31us/step - loss: 0.2811 - accuracy: 0.9096\n",
      "Epoch 63/150\n",
      "5556/5556 [==============================] - 0s 32us/step - loss: 0.2855 - accuracy: 0.9023\n",
      "Epoch 64/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.2769 - accuracy: 0.9077\n",
      "Epoch 65/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2729 - accuracy: 0.9102\n",
      "Epoch 66/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.2771 - accuracy: 0.9089\n",
      "Epoch 67/150\n",
      "5556/5556 [==============================] - 0s 27us/step - loss: 0.2731 - accuracy: 0.9077\n",
      "Epoch 68/150\n",
      "5556/5556 [==============================] - 0s 30us/step - loss: 0.2735 - accuracy: 0.9093\n",
      "Epoch 69/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2746 - accuracy: 0.9095\n",
      "Epoch 70/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2675 - accuracy: 0.9116\n",
      "Epoch 71/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2687 - accuracy: 0.9111\n",
      "Epoch 72/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2667 - accuracy: 0.9129\n",
      "Epoch 73/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.2656 - accuracy: 0.9118\n",
      "Epoch 74/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2653 - accuracy: 0.9098\n",
      "Epoch 75/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2649 - accuracy: 0.9113\n",
      "Epoch 76/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2643 - accuracy: 0.9129\n",
      "Epoch 77/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2652 - accuracy: 0.9127\n",
      "Epoch 78/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2695 - accuracy: 0.9078\n",
      "Epoch 79/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2666 - accuracy: 0.9122\n",
      "Epoch 80/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2612 - accuracy: 0.9129\n",
      "Epoch 81/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2607 - accuracy: 0.9141\n",
      "Epoch 82/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2609 - accuracy: 0.9127\n",
      "Epoch 83/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2598 - accuracy: 0.9122\n",
      "Epoch 84/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2588 - accuracy: 0.9127\n",
      "Epoch 85/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2573 - accuracy: 0.9143\n",
      "Epoch 86/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2650 - accuracy: 0.9098\n",
      "Epoch 87/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2662 - accuracy: 0.9068\n",
      "Epoch 88/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2690 - accuracy: 0.9098\n",
      "Epoch 89/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2698 - accuracy: 0.9073\n",
      "Epoch 90/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2664 - accuracy: 0.9107\n",
      "Epoch 91/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2660 - accuracy: 0.9118\n",
      "Epoch 92/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2839 - accuracy: 0.9015\n",
      "Epoch 93/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2708 - accuracy: 0.9068\n",
      "Epoch 94/150\n",
      "5556/5556 [==============================] - 0s 28us/step - loss: 0.2583 - accuracy: 0.9129\n",
      "Epoch 95/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2635 - accuracy: 0.9113\n",
      "Epoch 96/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2683 - accuracy: 0.9062\n",
      "Epoch 97/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2574 - accuracy: 0.9125\n",
      "Epoch 98/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2547 - accuracy: 0.9122\n",
      "Epoch 99/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2516 - accuracy: 0.9141\n",
      "Epoch 100/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2550 - accuracy: 0.9143\n",
      "Epoch 101/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2612 - accuracy: 0.9114\n",
      "Epoch 102/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2538 - accuracy: 0.9145\n",
      "Epoch 103/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2505 - accuracy: 0.9149\n",
      "Epoch 104/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2516 - accuracy: 0.9156\n",
      "Epoch 105/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2602 - accuracy: 0.9143\n",
      "Epoch 106/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2500 - accuracy: 0.9156\n",
      "Epoch 107/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2529 - accuracy: 0.9143\n",
      "Epoch 108/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2530 - accuracy: 0.9145\n",
      "Epoch 109/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2559 - accuracy: 0.9159\n",
      "Epoch 110/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2574 - accuracy: 0.9120\n",
      "Epoch 111/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2502 - accuracy: 0.9143\n",
      "Epoch 112/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2469 - accuracy: 0.9158\n",
      "Epoch 113/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2565 - accuracy: 0.9147\n",
      "Epoch 114/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2571 - accuracy: 0.9107\n",
      "Epoch 115/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2518 - accuracy: 0.9136\n",
      "Epoch 116/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2652 - accuracy: 0.9078\n",
      "Epoch 117/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2593 - accuracy: 0.9109\n",
      "Epoch 118/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2549 - accuracy: 0.9136\n",
      "Epoch 119/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2520 - accuracy: 0.9141\n",
      "Epoch 120/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2506 - accuracy: 0.9156\n",
      "Epoch 121/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2492 - accuracy: 0.9156\n",
      "Epoch 122/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2472 - accuracy: 0.9172\n",
      "Epoch 123/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.2513 - accuracy: 0.9154\n",
      "Epoch 124/150\n",
      "5556/5556 [==============================] - 0s 42us/step - loss: 0.2485 - accuracy: 0.9158\n",
      "Epoch 125/150\n",
      "5556/5556 [==============================] - 0s 30us/step - loss: 0.2479 - accuracy: 0.9167\n",
      "Epoch 126/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2504 - accuracy: 0.9163\n",
      "Epoch 127/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2468 - accuracy: 0.9163\n",
      "Epoch 128/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2548 - accuracy: 0.9125\n",
      "Epoch 129/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.2512 - accuracy: 0.9159\n",
      "Epoch 130/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2477 - accuracy: 0.9161\n",
      "Epoch 131/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2476 - accuracy: 0.9176\n",
      "Epoch 132/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.2482 - accuracy: 0.9185\n",
      "Epoch 133/150\n",
      "5556/5556 [==============================] - 0s 29us/step - loss: 0.2480 - accuracy: 0.9167\n",
      "Epoch 134/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2471 - accuracy: 0.9183\n",
      "Epoch 135/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2456 - accuracy: 0.9176\n",
      "Epoch 136/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2538 - accuracy: 0.9136\n",
      "Epoch 137/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2514 - accuracy: 0.9143\n",
      "Epoch 138/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2450 - accuracy: 0.9181\n",
      "Epoch 139/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2486 - accuracy: 0.9156\n",
      "Epoch 140/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2517 - accuracy: 0.9140\n",
      "Epoch 141/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2615 - accuracy: 0.9154\n",
      "Epoch 142/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2546 - accuracy: 0.9141\n",
      "Epoch 143/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2461 - accuracy: 0.9172\n",
      "Epoch 144/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2548 - accuracy: 0.9172\n",
      "Epoch 145/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2556 - accuracy: 0.9122\n",
      "Epoch 146/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2502 - accuracy: 0.9141\n",
      "Epoch 147/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2480 - accuracy: 0.9168\n",
      "Epoch 148/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2413 - accuracy: 0.9194\n",
      "Epoch 149/150\n",
      "5556/5556 [==============================] - 0s 18us/step - loss: 0.2509 - accuracy: 0.9170\n",
      "Epoch 150/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2466 - accuracy: 0.9159\n",
      "1389/1389 [==============================] - 0s 108us/step\n",
      "i 3\n",
      "Epoch 1/150\n",
      "5556/5556 [==============================] - 0s 87us/step - loss: 0.6675 - accuracy: 0.5344\n",
      "Epoch 2/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.6610 - accuracy: 0.5889\n",
      "Epoch 3/150\n",
      "5556/5556 [==============================] - 0s 30us/step - loss: 0.6027 - accuracy: 0.7300\n",
      "Epoch 4/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.5299 - accuracy: 0.8434\n",
      "Epoch 5/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.4834 - accuracy: 0.8639\n",
      "Epoch 6/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.4581 - accuracy: 0.8798\n",
      "Epoch 7/150\n",
      "5556/5556 [==============================] - 0s 34us/step - loss: 0.4172 - accuracy: 0.8817\n",
      "Epoch 8/150\n",
      "5556/5556 [==============================] - 0s 46us/step - loss: 0.3867 - accuracy: 0.8866\n",
      "Epoch 9/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.3643 - accuracy: 0.8909\n",
      "Epoch 10/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.4014 - accuracy: 0.8479\n",
      "Epoch 11/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.3565 - accuracy: 0.8850\n",
      "Epoch 12/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.5826 - accuracy: 0.8688\n",
      "Epoch 13/150\n",
      "5556/5556 [==============================] - 0s 42us/step - loss: 0.3708 - accuracy: 0.8681\n",
      "Epoch 14/150\n",
      "5556/5556 [==============================] - 0s 29us/step - loss: 0.3262 - accuracy: 0.8830\n",
      "Epoch 15/150\n",
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.3149 - accuracy: 0.9001\n",
      "Epoch 16/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.3046 - accuracy: 0.8961\n",
      "Epoch 17/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2894 - accuracy: 0.9044\n",
      "Epoch 18/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2782 - accuracy: 0.9062\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5556/5556 [==============================] - 0s 24us/step - loss: 0.2872 - accuracy: 0.9037\n",
      "Epoch 20/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2766 - accuracy: 0.9046\n",
      "Epoch 21/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2615 - accuracy: 0.9107\n",
      "Epoch 22/150\n",
      "5556/5556 [==============================] - 0s 22us/step - loss: 0.2460 - accuracy: 0.9188\n",
      "Epoch 23/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2654 - accuracy: 0.9066\n",
      "Epoch 24/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.2432 - accuracy: 0.9221\n",
      "Epoch 25/150\n",
      "5556/5556 [==============================] - 0s 20us/step - loss: 0.2536 - accuracy: 0.9134\n",
      "Epoch 26/150\n",
      "5556/5556 [==============================] - 0s 21us/step - loss: 0.2256 - accuracy: 0.9282\n",
      "Epoch 27/150\n",
      "5556/5556 [==============================] - 0s 25us/step - loss: 0.2212 - accuracy: 0.9282\n",
      "Epoch 28/150\n",
      "5556/5556 [==============================] - 0s 19us/step - loss: 0.2330 - accuracy: 0.9240\n",
      "Epoch 29/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2230 - accuracy: 0.9257\n",
      "Epoch 30/150\n",
      "5556/5556 [==============================] - 0s 23us/step - loss: 0.2186 - accuracy: 0.9266\n",
      "Epoch 31/150\n",
      "5556/5556 [==============================] - 0s 26us/step - loss: 0.2438 - accuracy: 0.9113\n",
      "Epoch 32/150\n",
      "5556/5556 [==============================] - 0s 17us/step - loss: 0.2397 - accuracy: 0.9201\n",
      "Epoch 33/150\n",
      "5556/5556 [==============================] - 0s 16us/step - loss: 0.2600 - accuracy: 0.9156\n",
      "Epoch 34/150\n",
      " 150/5556 [..............................] - ETA: 0s - loss: 0.2838 - accuracy: 0.8933"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c4e4e77b9d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# fit the keras model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# evaluate the keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#initialisations\n",
    "max_iterations=10\n",
    "number_of_hidden_layers=0\n",
    "step=2\n",
    "\n",
    "\n",
    "accuracy_list=[[0]*2 for _ in range(max_iterations)]\n",
    "# define the keras model\n",
    "\n",
    "for i in range(0,max_iterations):\n",
    "    model = Sequential()\n",
    "    # tanh and relu -check\n",
    "    \n",
    "    model.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "    \n",
    "    for j in range(number_of_hidden_layers):\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "            \n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "#     model.add(Dense(5, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "\n",
    "    # evaluate the keras model\n",
    "    _,accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(\"i\",i)\n",
    "    accuracy_list[i][0]=number_of_hidden_layers\n",
    "    accuracy_list[i][1]=accuracy\n",
    "#     accuracy_list.append[number_of_hidden_layers , accuracy]\n",
    "    \n",
    "    number_of_hidden_layers+=step\n",
    "\n",
    "#     print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(accuracy_list)):\n",
    "    print(accuracy_list[i][0],\"\\t\",accuracy_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of hidden layers vs accuracy\n",
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Activation Functions\n",
    "\n",
    "Output layer will have Sigmoid function. Different combinations of Tanh and ReLU activation functions will be used to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model1 = Sequential()\n",
    "# tanh and relu -check\n",
    "\n",
    "#add hidden layers\n",
    "#experimentally it was found that when ReLU activation function was applied to all the layers, the model gave the best result.\n",
    "model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model1.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "\n",
    "# evaluate the model\n",
    "_,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model1 = Sequential()\n",
    "# tanh and relu -check\n",
    "\n",
    "#add hidden layers\n",
    "model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "model1.add(Dense(4, activation='tanh'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(4, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "model1.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "\n",
    "# evaluate the model\n",
    "_,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Number of neurons in hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iterations=10\n",
    "number_of_neurons=2\n",
    "step=2\n",
    "\n",
    "\n",
    "accuracy_list=[[0]*2 for _ in range(max_iterations)]\n",
    "# define the keras model\n",
    "\n",
    "for i in range(0,max_iterations):  \n",
    "    model2 = Sequential()\n",
    "    # tanh and relu -check\n",
    "    \n",
    "    #add hidden layers\n",
    "    model2.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(number_of_neurons, activation='relu'))\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model2.fit(X_train, y_train, epochs=150, batch_size=150)\n",
    "    \n",
    "    # evaluate the model\n",
    "    _,accuracy = model2.evaluate(X_test, y_test)\n",
    "\n",
    "    accuracy_list[i][0]=number_of_neurons\n",
    "    accuracy_list[i][1]=accuracy*100\n",
    "#     print('Accuracy: %.2f' % (accuracy*100))\n",
    "    print(accuracy_list[i][1])\n",
    "    number_of_neurons += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(accuracy_list)):\n",
    "    print(accuracy_list[i][0],\"\\t\",accuracy_list[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Number of Ephocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations=100\n",
    "number_of_ephocs=0\n",
    "step=10\n",
    "\n",
    "\n",
    "accuracy_list=[[0]*2 for _ in range(max_iterations)]\n",
    "# define the keras model\n",
    "\n",
    "for i in range(0,max_iterations):\n",
    "    model1 = Sequential()\n",
    "\n",
    "    model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(10, activation='relu'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history=model1.fit(X_train, y_train, epochs=number_of_ephocs, batch_size=150,validation_split=0.30)\n",
    "    \n",
    "    # evaluate the model\n",
    "    number_of_ephocs+=step\n",
    "    _,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "    print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: TRAIN THE FINAL MODEL\n",
    "\n",
    "Using fine-tuned hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "#Arcitecture of the ANN\n",
    "model1.add(Dense(15, input_dim=len(features), activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "history = model1.fit(X_train, y_train, epochs=375, batch_size=150,validation_split=0.30,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389/1389 [==============================] - 0s 64us/step\n",
      "Accuracy: 97.26\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "_,accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label = model1.predict_classes(X_test)\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.reshape(X_test[test_case:test_case+1],(6,)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: EVALUATION OF CLASSIFICATION RESULTS\n",
    "\n",
    "The classifier will be evaluted using Accuracy, Recall, Precision and F-measure. For this first, a confusion matrix will be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict =   model1.predict_classes(X_test)                #to store prediction of each test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_negative\n",
    "TN = conf_matrix[0][0]\n",
    "\n",
    "#false_negative\n",
    "FN = conf_matrix[1][0]\n",
    "\n",
    "#false_positive\n",
    "FP = conf_matrix[0][1]\n",
    "\n",
    "#true_positive\n",
    "TP = conf_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall is the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "# High Recall indicates the class is correctly recognized (small number of FN)\n",
    "\n",
    "recall = (TP)/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (TP)/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure = (2*recall*precision)/(recall+precision)\n",
    "accuracy = (TP + TN)/(TN + FN + FP + TP)\n",
    "#accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ CLASSIFICATION PERFORMANCE OF THE NEURAL NETWORKS MODEL ------ \\n\"\\\n",
    "      \"\\n Recall : \", (recall*100) ,\"%\" \\\n",
    "      \"\\n Precision : \", (precision*100) ,\"%\" \\\n",
    "      \"\\n Accuracy : \", (accuracy*100) ,\"%\" \\\n",
    "      \"\\n F-measure : \", (fmeasure*100) ,\"%\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())    #to list all data in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy and Loss plotting\n",
    "def plot(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
