{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/twitter_dataset.csv', encoding = 'latin-1')\n",
    "# dataset.head()           #show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinig attributes into single list of tuples and using those features create a 2D matrix \n",
    "\n",
    "# features = ['name_wt','statuses_count', 'followers_count', 'friends_count','favourites_count','listed_count']\n",
    "data = dataset.values\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.000e-01, 2.177e+03, 2.080e+02, ..., 2.650e+02, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [4.000e-01, 2.660e+03, 3.300e+02, ..., 3.972e+03, 5.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.750e-01, 1.254e+03, 1.660e+02, ..., 1.185e+03, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [4.375e-01, 1.700e+01, 5.300e+02, ..., 0.000e+00, 8.000e+00,\n",
       "        1.000e+00],\n",
       "       [4.375e-01, 2.000e+00, 2.470e+02, ..., 0.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [3.500e-01, 4.700e+01, 2.670e+02, ..., 0.000e+00, 7.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=dataset.values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Total instances : \", data.shape[0], \"\\nNumber of features : \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert label column into 1D arrray\n",
    "\n",
    "label = np.array(dataset['label'])\n",
    "# label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train Split\n",
    "\n",
    "Using 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of training instances: \", X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of testing instances: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "data = X_train\n",
    "label = y_train\n",
    "\n",
    "nb_model.fit(data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "Now our model is ready. We will test our data against given labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model.predict([X_test[1]])    #testing for single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   Now, apply the model to the entire test set and predict the label for each test example\n",
    "\n",
    "'''       \n",
    "       \n",
    "y_predict = []                       #to store prediction of each test example\n",
    "\n",
    "for test_case in range(len(X_test)): \n",
    "    label = nb_model.predict([X_test[test_case]])\n",
    "    \n",
    "    #append to the predictions list\n",
    "    y_predict.append(np.asscalar(label))\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perormance evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true negatives is C(0,0), false negatives is C(1,0), false positives is C(0,1) and true positives is C(1,1) \n",
    "conf_matrix = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_negative\n",
    "TN = conf_matrix[0][0]\n",
    "#false_negative\n",
    "FN = conf_matrix[1][0]\n",
    "#false_positive\n",
    "FP = conf_matrix[0][1]\n",
    "#true_positive\n",
    "TP = conf_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall is the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "# High Recall indicates the class is correctly recognized (small number of FN)\n",
    "recall = (TP)/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision is the the total number of correctly classified positive examples divided by the total number of predicted positive examples. \n",
    "# High Precision indicates an example labeled as positive is indeed positive (small number of FP)\n",
    "precision = (TP)/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure = (2*recall*precision)/(recall+precision)\n",
    "accuracy = (TP + TN)/(TN + FN + FP + TP)\n",
    "#accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " Recall :  95.55125725338492 %\n",
      " Precision :  75.19025875190259 %\n",
      " Accuracy :  84.76658476658476 %\n",
      " F-measure :  84.15672913117547 %\n"
     ]
    }
   ],
   "source": [
    "print(\"------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \"\\\n",
    "      \"\\n Recall : \", (recall*100) ,\"%\" \\\n",
    "      \"\\n Precision : \", (precision*100) ,\"%\" \\\n",
    "      \"\\n Accuracy : \", (accuracy*100) ,\"%\" \\\n",
    "      \"\\n F-measure : \", (fmeasure*100) ,\"%\" )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
