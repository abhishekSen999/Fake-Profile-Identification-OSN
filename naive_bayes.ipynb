{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/twitter_dataset2.csv', encoding = 'latin-1')\n",
    "# dataset.head()           #show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6102, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['principal_component_1', 'principal_component_2']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[]\n",
    "for attributes in dataset.columns:\n",
    "    if attributes != 'label':\n",
    "        features.append(attributes)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Combinig attributes into single list of tuples and using those features create a 2D matrix \n",
    "\n",
    "data = dataset.as_matrix(columns = features)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1650233 ,  0.12898345,  0.        ],\n",
       "       [-0.11202845,  0.12251322,  0.        ],\n",
       "       [-0.18998819, -0.07067798,  0.        ],\n",
       "       ...,\n",
       "       [-0.16363841, -0.27620893,  1.        ],\n",
       "       [-0.19344886, -0.27389917,  1.        ],\n",
       "       [-0.18018864, -0.15262564,  1.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=dataset.values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Total instances : \", data.shape[0], \"\\nNumber of features : \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert label column into 1D arrray\n",
    "\n",
    "label = np.array(dataset['label'])\n",
    "# label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train Split\n",
    "\n",
    "Using 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of training instances: \", X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of testing instances: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "data = X_train\n",
    "label = y_train\n",
    "\n",
    "nb_model.fit(data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "Now our model is ready. We will test our data against given labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model.predict([X_test[1]])    #testing for single instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   Now, apply the model to the entire test set and predict the label for each test example\n",
    "\n",
    "'''       \n",
    "       \n",
    "y_predict = []                       #to store prediction of each test example\n",
    "\n",
    "for test_case in range(len(X_test)): \n",
    "    label = nb_model.predict([X_test[test_case]])\n",
    "    \n",
    "    #append to the predictions list\n",
    "    y_predict.append(np.asscalar(label))\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perormance evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true negatives is C(0,0), false negatives is C(1,0), false positives is C(0,1) and true positives is C(1,1) \n",
    "conf_matrix = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_negative\n",
    "TN = conf_matrix[0][0]\n",
    "#false_negative\n",
    "FN = conf_matrix[1][0]\n",
    "#false_positive\n",
    "FP = conf_matrix[0][1]\n",
    "#true_positive\n",
    "TP = conf_matrix[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall is the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "# High Recall indicates the class is correctly recognized (small number of FN)\n",
    "recall = (TP)/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision is the the total number of correctly classified positive examples divided by the total number of predicted positive examples. \n",
    "# High Precision indicates an example labeled as positive is indeed positive (small number of FP)\n",
    "precision = (TP)/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure = (2*recall*precision)/(recall+precision)\n",
    "accuracy = (TP + TN)/(TN + FN + FP + TP)\n",
    "#accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \n",
      " Recall :  100.0 %\n",
      " Precision :  100.0 %\n",
      " Accuracy :  100.0 %\n",
      " F-measure :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"------ CLASSIFICATION PERFORMANCE OF THE NAIVE BAYES MODEL ------ \"\\\n",
    "      \"\\n Recall : \", (recall*100) ,\"%\" \\\n",
    "      \"\\n Precision : \", (precision*100) ,\"%\" \\\n",
    "      \"\\n Accuracy : \", (accuracy*100) ,\"%\" \\\n",
    "      \"\\n F-measure : \", (fmeasure*100) ,\"%\" )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
